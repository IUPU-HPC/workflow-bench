#!/bin/bash
#SBATCH --job-name="lammps_decaf"
#SBATCH --output="results/%j.out"
#SBATCH --partition=normal
#SBATCH --nodes=4
#SBATCH --ntasks-per-node=68
#SBATCH -t 00:8:00

#SBATCH --mail-type=BEGIN
# send mail to this address
#SBATCH --mail-user=lifen@iupui.edu

NSTOP=10

# procs placement
num_apps=3

# slots used by this app
procs_this_app=(68 64 34)

# number of nodes used by this app
nodes_this_app=(2 1 1)


PBS_O_HOME=$HOME
PBS_O_WORKDIR=$(pwd)
export SCRATCH_DIR=${SCRATCH}/lammps_decaf/${SLURM_JOBID}


#################################################### 

env|grep '^HAS' # trace enabled?
env|grep '^OMP' # trace enabled?

#module load remora

#module load libfabric
module load boost
module load phdf5
module list



echo "procs is \[ ${procs_this_app[*]}\], nodes is \[${nodes_this_app[*]}\]"

export BUILD_DIR=${PBS_O_WORKDIR}/build

#This job runs with 3 nodes  
#ibrun in verbose mode will give binding detail  #BUILD=${PBS_O_WORKDIR}/build_dspaces/bin
PBS_RESULTDIR=${SCRATCH_DIR}/results



mkdir -pv ${PBS_RESULTDIR}
tune_stripe_count=-1
lfs setstripe --stripe-size 1m --stripe-count ${tune_stripe_count} ${PBS_RESULTDIR}
mkdir -pv ${SCRATCH_DIR}
cd ${SCRATCH_DIR}
#cp -R ${PBS_O_WORKDIR}/global_range_select/arrays.xml ${SCRATCH_DIR}


# this scrWorkspaces/General_Data_Broker/lbm_adios/scripts
GENERATE_HOST_SCRIPT=${PBS_O_WORKDIR}/scripts/generate_hosts.sh
#GENERATE_HOST_SCRIPT=${HOME}/Downloads/LaucherTest/generate_hosts.sh
if [ -a $GENERATE_HOST_SCRIPT ]; then
    source $GENERATE_HOST_SCRIPT
else
    echo "generate_hosts.sh should downloaded from:"
    echo "https://github.iu.edu/lifen/LaucherTest/blob/master/generate_hosts.sh"
fi

export procs_prod=${procs_this_app[0]}
export procs_link=${procs_this_app[1]}
export procs_con=${procs_this_app[2]}

procs_all=$((procs_prod + procs_con + procs_link))

# generate graph
PYTHON_RUN="python $PBS_O_WORKDIR/decaf/lammps_decaf.py --np ${procs_all} --hostfile ${HOST_DIR}/machinefile-all"
$PYTHON_RUN &> python.log
echo "python run $PYTHON_RUN"

# copy input file
#infile=in.melt
infile=in.lj.68v34.txt
cp ${PBS_O_WORKDIR}/lammps/$infile ./$infile

cmd="$BUILD_DIR/bin/lammps $NSTOP $infile"

## order is prod/link/consumer
MPI_CMD="mpirun -l  --machinefile ${HOST_DIR}/machinefile-all -np ${procs_prod} $cmd : -np ${procs_link} $cmd : -np ${procs_con} $cmd"
echo launch mpi with cmd $MPI_CMD

$MPI_CMD

## Wait for the entire workflow to finish
wait



