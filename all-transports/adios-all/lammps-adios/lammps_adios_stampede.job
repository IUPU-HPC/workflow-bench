#!/bin/bash
#SBATCH --job-name="lammps_adios"
#SBATCH --output="results/%j.out"
#SBATCH --partition=normal
#SBATCH --nodes=3
#SBATCH --ntasks-per-node=68
#SBATCH -t 00:8:00

#SBATCH --mail-type=BEGIN
# send mail to this address
#SBATCH --mail-user=lifen@iupui.edu

NSTOP=10

# procs placement
num_apps=2

# slots used by this app
procs_this_app=(68 34)

# number of nodes used by this app
nodes_this_app=(2 1)


PBS_O_HOME=$HOME
PBS_O_WORKDIR=$(pwd)
export SCRATCH_DIR=${SCRATCH}/lammps_adios/${SLURM_JOBID}


#################################################### 

export MyTransport=ADIOS_STAGING_FLEXPATH

export OMP_NUM_THREADS=4

export CM_INTERFACE=ib0

env|grep '^CM'
env|grep '^HAS' # trace enabled?
env|grep '^OMP' # trace enabled?


module list

if [ x"$HAS_TRACE" == "x" ];then
    BUILD_DIR=${PBS_O_WORKDIR}/build
    DS_SERVER=${WORK}/envs/gcc_mvapich/Dataspacesroot/bin/dataspaces_server

elif [ x"$HAS_TRACE" = "xitac" ]; then
    #export LD_PRELOAD=libVT.so
    NSTOP=10
    echo "itac ENABLED, use 10 steps"
    export BUILD_DIR=${PBS_O_WORKDIR}/build_itac
    echo "use itac"
    export VT_LOGFILE_PREFIX=${SCRATCH_DIR}/trace 
    export VT_VERBOSE=3
    mkdir -pv $VT_LOGFILE_PREFIX

else
    echo "TRACE ENABLED"
    BUILD_DIR=${PBS_O_WORKDIR}/build_tau
    DS_SERVER=${WORK}/envs/Dataspacesroot_tau/bin/dataspaces_server
    #enable trace
    export TAU_TRACE=1
    # set trace dir
    export ALL_TRACES=${SCRATCH_DIR}/trace
    mkdir -pv $ALL_TRACES/app0
    mkdir -pv $ALL_TRACES/app1
    mkdir -pv $ALL_TRACES/app2

    if [ -z $TAU_MAKEFILE ]; then
        module load tau
        echo "LOAD TAU!"
    fi

fi



echo "procs is \[ ${procs_this_app[*]}\], nodes is \[${nodes_this_app[*]}\]"


#This job runs with 3 nodes  
#ibrun in verbose mode will give binding detail  #BUILD=${PBS_O_WORKDIR}/build_dspaces/bin
PBS_RESULTDIR=${SCRATCH_DIR}/results



mkdir -pv ${PBS_RESULTDIR}
tune_stripe_count=-1
lfs setstripe --stripe-size 1m --stripe-count ${tune_stripe_count} ${PBS_RESULTDIR}
mkdir -pv ${SCRATCH_DIR}
cd ${SCRATCH_DIR}
#cp -R ${PBS_O_WORKDIR}/global_range_select/arrays.xml ${SCRATCH_DIR}

cp -R ${PBS_O_WORKDIR}/adios/xmls ${SCRATCH_DIR}


# this scrWorkspaces/General_Data_Broker/lbm_adios/scripts
GENERATE_HOST_SCRIPT=${PBS_O_WORKDIR}/scripts/generate_hosts.sh
#GENERATE_HOST_SCRIPT=${HOME}/Downloads/LaucherTest/generate_hosts.sh
if [ -a $GENERATE_HOST_SCRIPT ]; then
    source $GENERATE_HOST_SCRIPT
else
    echo "generate_hosts.sh should downloaded from:"
    echo "https://github.iu.edu/lifen/LaucherTest/blob/master/generate_hosts.sh"
fi

export procs_prod=${procs_this_app[0]}
#export procs_link=${procs_this_app[1]}
export procs_con=${procs_this_app[1]}

procs_all=$((procs_prod + procs_con))

infile=in.lj.68v34.txt
cp ${PBS_O_WORKDIR}/lammps/$infile ./$infile

cmd_prod="$BUILD_DIR/bin/lammps_adios_prod $NSTOP $infile"
cmd_con="$BUILD_DIR/bin/lammps_adios_con $NSTOP"

## order is prod/link/consumer
MPI_CMD1="mpirun -l  --machinefile $HOST_DIR/machinefile-app0 -np ${procs_prod} $cmd_prod"

MPI_CMD2="mpirun -l  --machinefile $HOST_DIR/machinefile-app1 -np ${procs_con} $cmd_con"

$MPI_CMD1 &> prod.log &
$MPI_CMD2 &> con.log &

## Wait for the entire workflow to finish
wait



